{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rohai087/test/blob/main/Untitled6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install -q tensorflow-datasets scikit-learn opencv-python-headless seaborn\n"
      ],
      "metadata": {
        "id": "ckmHyRtWjK07"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import json\n",
        "\n",
        "print(\"TF version:\", tf.__version__)\n",
        "print(\"GPUs:\", tf.config.list_physical_devices('GPU'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqgJAqrXjPlS",
        "outputId": "d7c4c443-7d1b-491f-8c1f-31278bcdd8ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _xla_gc_callback at 0x7f7476baba60>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jax/_src/lib/__init__.py\", line 127, in _xla_gc_callback\n",
            "    def _xla_gc_callback(*args):\n",
            "    \n",
            "KeyboardInterrupt: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ds_all, ds_info = tfds.load(\"caltech101\", split=\"train\", with_info=True, as_supervised=True)\n",
        "\n",
        "num_examples = ds_info.splits['train'].num_examples\n",
        "num_classes = ds_info.features['label'].num_classes\n",
        "class_names = ds_info.features['label'].names\n",
        "\n",
        "print(\"Examples:\", num_examples)\n",
        "print(\"Num classes:\", num_classes)\n",
        "print(\"Class sample (first 10):\", class_names[:10])\n"
      ],
      "metadata": {
        "id": "wRFUpBtajSNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "SEED = 42\n",
        "ds = ds_all.shuffle(10000, seed=SEED, reshuffle_each_iteration=False)\n",
        "\n",
        "train_count = int(0.80 * num_examples)\n",
        "val_count   = int(0.10 * num_examples)\n",
        "test_count  = num_examples - train_count - val_count\n",
        "\n",
        "print(\"Splits (train,val,test):\", train_count, val_count, test_count)\n",
        "\n",
        "train_ds = ds.take(train_count)\n",
        "rest_ds = ds.skip(train_count)\n",
        "val_ds = rest_ds.take(val_count)\n",
        "test_ds = rest_ds.skip(val_count)\n",
        "\n",
        "\n",
        "print(\"Train, Val, Test sizes:\",\n",
        "      tf.data.experimental.cardinality(train_ds).numpy(),\n",
        "      tf.data.experimental.cardinality(val_ds).numpy(),\n",
        "      tf.data.experimental.cardinality(test_ds).numpy())\n"
      ],
      "metadata": {
        "id": "FOnUkUfmjW8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "IMG_SIZE = 128\n",
        "BATCH_SIZE = 32\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "def preprocess_image(image, label):\n",
        "\n",
        "    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    return image, label\n",
        "\n",
        "\n",
        "data_augmentation = keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.08),\n",
        "    layers.RandomZoom(0.08),\n",
        "    layers.RandomTranslation(0.05, 0.05),\n",
        "], name=\"data_augmentation\")\n",
        "\n",
        "def prepare(ds, training=False):\n",
        "    ds = ds.map(preprocess_image, num_parallel_calls=AUTOTUNE)\n",
        "    if training:\n",
        "        ds = ds.map(lambda x,y: (data_augmentation(x, training=True), y), num_parallel_calls=AUTOTUNE)\n",
        "        ds = ds.shuffle(2000)\n",
        "    ds = ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
        "    return ds\n",
        "\n",
        "train_ds = prepare(train_ds, training=True)\n",
        "val_ds   = prepare(val_ds, training=False)\n",
        "test_ds  = prepare(test_ds, training=False)\n"
      ],
      "metadata": {
        "id": "BE5ufTjojdha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def build_cnn(input_shape=(IMG_SIZE,IMG_SIZE,3), num_classes=num_classes):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    x = layers.Conv2D(32, (3,3), padding='same', activation=None)(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.MaxPool2D((2,2))(x)\n",
        "\n",
        "    x = layers.Conv2D(64, (3,3), padding='same', activation=None)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.MaxPool2D((2,2))(x)\n",
        "    x = layers.Dropout(0.25)(x)\n",
        "\n",
        "    x = layers.Conv2D(128, (3,3), padding='same', activation=None)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.MaxPool2D((2,2))(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    x = layers.Conv2D(256, (3,3), padding='same', activation=None)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dropout(0.4)(x)\n",
        "\n",
        "    x = layers.Dense(256, activation='relu')(x)\n",
        "    x = layers.Dropout(0.4)(x)\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = keras.Model(inputs, outputs, name=\"caltech101_cnn\")\n",
        "    return model\n",
        "\n",
        "model = build_cnn()\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "K0ht3A0ijl9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 7:\n",
        "initial_lr = 1e-3\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=initial_lr),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ],
      "metadata": {
        "id": "-fY5e948jrQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "checkpoint_path = \"best_caltech101_model.h5\"\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(checkpoint_path, monitor=\"val_accuracy\", save_best_only=True, verbose=1),\n",
        "    keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, verbose=1),\n",
        "    keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=7, restore_best_weights=True, verbose=1)\n",
        "]\n"
      ],
      "metadata": {
        "id": "BbtpogKOjvwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "EPOCHS = 20\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=callbacks\n",
        ")\n"
      ],
      "metadata": {
        "id": "h7tHJe_6jzJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def plot_history(h):\n",
        "    plt.figure(figsize=(12,4))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(h.history['loss'], label='train_loss')\n",
        "    plt.plot(h.history['val_loss'], label='val_loss')\n",
        "    plt.legend(); plt.title('Loss')\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(h.history['accuracy'], label='train_acc')\n",
        "    plt.plot(h.history['val_accuracy'], label='val_acc')\n",
        "    plt.legend(); plt.title('Accuracy')\n",
        "    plt.show()\n",
        "\n",
        "plot_history(history)\n"
      ],
      "metadata": {
        "id": "BJSVPTdKx7DV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if os.path.exists(checkpoint_path):\n",
        "    model = keras.models.load_model(checkpoint_path)\n",
        "    print(\"Loaded best model from checkpoint.\")\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_ds)\n",
        "print(f\"Test loss: {test_loss:.4f}, Test accuracy: {test_acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "0vBhd3ElyFLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 12 (REPLACEMENT): Predictions, classification report, confusion matrix (robust) ===\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Get predictions on test_ds\n",
        "y_pred_probs = model.predict(test_ds)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "# Extract true labels in same order as test_ds\n",
        "y_true = np.concatenate([y for x,y in test_ds], axis=0)\n",
        "\n",
        "# Diagnostics\n",
        "print(\"Shapes -> y_true:\", y_true.shape, \" y_pred:\", y_pred.shape)\n",
        "unique_true = np.unique(y_true)\n",
        "unique_pred = np.unique(y_pred)\n",
        "print(\"Unique labels in y_true:\", unique_true.shape[0], \" (example first 10):\", unique_true[:10])\n",
        "print(\"Unique labels in y_pred:\", unique_pred.shape[0], \" (example first 10):\", unique_pred[:10])\n",
        "print(\"Total class_names length:\", len(class_names))\n",
        "\n",
        "\n",
        "labels = sorted(list(set(np.concatenate([unique_true, unique_pred]))))\n",
        "s\n",
        "if max(labels) >= len(class_names) or min(labels) < 0:\n",
        "    raise ValueError(f\"Found label indices outside range of class_names (0..{len(class_names)-1}).\")\n",
        "\n",
        "ls\n",
        "class_names_filtered = [class_names[i] for i in labels]\n",
        "\n",
        "print(f\"Using {len(labels)} labels for the report. Example labels: {labels[:10]}\")\n",
        "\n",
        "\n",
        "print(\"\\nClassification report (precision, recall, f1):\\n\")\n",
        "print(classification_report(y_true, y_pred, labels=labels, target_names=class_names_filtered, digits=4, zero_division=0))\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
        "\n",
        "# Plot confusion matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(14,12))\n",
        "sns.heatmap(cm, annot=False, cmap='Blues', xticklabels=class_names_filtered, yticklabels=class_names_filtered)\n",
        "plt.ylabel('True'); plt.xlabel('Predicted'); plt.title('Confusion Matrix (filtered labels)')\n",
        "plt.xticks(rotation=90)\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "hfdtCAwn0bhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "labels = sorted(list(set(y_true)))\n",
        "class_names_fixed = [class_names[i] for i in labels]\n",
        "\n",
        "print(classification_report(\n",
        "    y_true,\n",
        "    y_pred,\n",
        "    labels=labels,\n",
        "    target_names=class_names_fixed,\n",
        "    digits=4\n",
        "))\n"
      ],
      "metadata": {
        "id": "NzuktejLykdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 13: Show sample predictions (first N from test set) ===\n",
        "def show_samples_from_test(model, test_dataset, class_names, N=12):\n",
        "    # collect images and labels from first batch(es) until we have N\n",
        "    images = []\n",
        "    trues = []\n",
        "    for batch_images, batch_labels in test_dataset.unbatch().batch(1).take(N):\n",
        "        images.append(tf.cast(batch_images[0]*255.0, tf.uint8).numpy())\n",
        "        trues.append(int(batch_labels.numpy()))\n",
        "    images = np.array(images)\n",
        "    preds = np.argmax(model.predict(images/255.0), axis=1)\n",
        "\n",
        "    plt.figure(figsize=(14,8))\n",
        "    for i in range(N):\n",
        "        ax = plt.subplot(3, 4, i+1)\n",
        "        plt.imshow(images[i])\n",
        "        plt.title(f\"T: {class_names[trues[i]]}\\nP: {class_names[preds[i]]}\", fontsize=9)\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "show_samples_from_test(model, test_ds, class_names, N=12)\n"
      ],
      "metadata": {
        "id": "CccX7B6yyqmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"caltech101_cnn_model.keras\")\n",
        "print(\"Model saved successfully!\")\n"
      ],
      "metadata": {
        "id": "tzMQMY4Jy_ZF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}